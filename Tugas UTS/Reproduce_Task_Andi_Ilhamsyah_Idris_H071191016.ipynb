{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reproduce Task - Andi Ilhamsyah Idris H071191016.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4DcVGyYDkwh"
      },
      "outputs": [],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import numpy as np \n",
        "import random\n",
        "from PIL import Image\n",
        "from types import SimpleNamespace\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.reset_orig()\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path folder dimana datasets didownload\n",
        "DATASET_PATH = \"../data\"\n",
        "# Path folder dimana models akan disimpan\n",
        "CHECKPOINT_PATH = \"../saved_models/\"\n",
        "\n",
        "# Fungsi untuk mengatur seed\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "set_seed(42)\n",
        "\n",
        "# Memastikan semua operasi deterministik dengan GPU untuk reproduktivitas\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "BLsSQlf1RGpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "from urllib.error import HTTPError\n",
        "# Github URL dimana models disimpan\n",
        "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial5/\"\n",
        "# File yang didownload\n",
        "pretrained_files = [\"GoogleNet.ckpt\", \"ResNet.ckpt\", \"ResNetPreAct.ckpt\", \"DenseNet.ckpt\",\n",
        "                    \"tensorboards/GoogleNet/events.out.tfevents.googlenet\",\n",
        "                    \"tensorboards/ResNet/events.out.tfevents.resnet\",\n",
        "                    \"tensorboards/ResNetPreAct/events.out.tfevents.resnetpreact\",\n",
        "                    \"tensorboards/DenseNet/events.out.tfevents.densenet\"]\n",
        "# Buat tanda path jika tidak dapat diakses\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
        "\n",
        "# Setiap file diperiksa jika sudah ada. Jika tidak, file akan diunduh.\n",
        "for file_name in pretrained_files:\n",
        "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
        "    if \"/\" in file_name:\n",
        "        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n",
        "    if not os.path.isfile(file_path):\n",
        "        file_url = base_url + file_name\n",
        "        print(f\"Downloading {file_url}...\")\n",
        "        try:\n",
        "            urllib.request.urlretrieve(file_url, file_path)\n",
        "        except HTTPError as e:\n",
        "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including th"
      ],
      "metadata": {
        "id": "Agwep_a7S64D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CIFAR10(root=DATASET_PATH, train=True, download=True)"
      ],
      "metadata": {
        "id": "z_tUf0PmT_H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_MEANS = (train_dataset.data / 255.0).mean(axis=(0,1,2))\n",
        "DATA_STD = (train_dataset.data / 255.0).std(axis=(0,1,2))\n",
        "\n",
        "print(\"Data mean\", DATA_MEANS)\n",
        "print(\"Data std\", DATA_STD)"
      ],
      "metadata": {
        "id": "qXOSBkwIVXh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize(DATA_MEANS, DATA_STD)\n",
        "                                     ])\n",
        "# Untuk latihan, kita menambahkan sebuah augmentasi, Jaringan terlalu kuat dan akan overfit.\n",
        "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(DATA_MEANS, DATA_STD)\n",
        "                                     ])\n",
        "# Memuat set data pelatihan. Kita perlu membaginya menjadi bagian pelatihan dan validasi\n",
        "# Kita perlu melakukan sedikit trik karena set validasi tidak boleh menggunakan augmentasi.\n",
        "train_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=train_transform, download=True)\n",
        "val_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=test_transform, download=True)\n",
        "set_seed(42)\n",
        "train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
        "set_seed(42)\n",
        "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
        "\n",
        "# Memuat set test\n",
        "test_set = CIFAR10(root=DATASET_PATH, train=False, transform=test_transform, download=True)\n",
        "\n",
        "# Kami mendefinisikan satu set pemuat data yang dapat kami gunakan untuk berbagai keperluan nanti.\n",
        "train_loader = data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
        "val_loader = data.DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=4)\n",
        "test_loader = data.DataLoader(test_set, batch_size=128, shuffle=False, drop_last=False, num_workers=4)"
      ],
      "metadata": {
        "id": "k4nDmfBiZMPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, _ = next(iter(train_loader))\n",
        "print(\"Batch mean\", imgs.mean(dim=[0,2,3]))\n",
        "print(\"Batch std\", imgs.std(dim=[0,2,3]))"
      ],
      "metadata": {
        "id": "IcW1Q9uzaBBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_IMAGES = 4\n",
        "images = [train_dataset[idx][0] for idx in range(NUM_IMAGES)]\n",
        "orig_images = [Image.fromarray(train_dataset.data[idx]) for idx in range(NUM_IMAGES)]\n",
        "orig_images = [test_transform(img) for img in orig_images]\n",
        "\n",
        "img_grid = torchvision.utils.make_grid(torch.stack(images + orig_images, dim=0), nrow=4, normalize=True, pad_value=0.5)\n",
        "img_grid = img_grid.permute(1, 2, 0)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title(\"Augmentation examples on CIFAR10\")\n",
        "plt.imshow(img_grid)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "ZGv0llvmcCa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError: # Google Colab tidak menyediakan PyTorch Lightning instalan default. Maka dari itu, kami melakukannya di sini jika perlu\n",
        "    !pip install --quiet pytorch-lightning>=1.4\n",
        "    import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "Cx_AayEMdY1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengatur seed\n",
        "pl.seed_everything(42)"
      ],
      "metadata": {
        "id": "ePDdmGQle0fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFARModule(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, model_name, model_hparams, optimizer_name, optimizer_hparams):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
        "            model_hparams - Hyperparameters for the model, as dictionary.\n",
        "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
        "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Export hyperparamater ke file YAML dan buat \"self.hparams\" sebagai nama\n",
        "        self.save_hyperparameters()\n",
        "        # Buat model\n",
        "        self.model = create_model(model_name, model_hparams)\n",
        "        # Buat loss module\n",
        "        self.loss_module = nn.CrossEntropyLoss()\n",
        "        # Example input untuk visualisasi grafik di Tensorboard\n",
        "        self.example_input_array = torch.zeros((1, 3, 32, 32), dtype=torch.float32)\n",
        "\n",
        "    def forward(self, imgs):\n",
        "        # Forward function berjalan ketika mengvisualisasikan grafik\n",
        "        return self.model(imgs)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Kita akan support Adam atau SGD sebagai optimalisasi.\n",
        "        if self.hparams.optimizer_name == \"Adam\":\n",
        "            # AdamW adalah Adam dengan implementasi yang benar terhadap penurunan beban (see here for details: https://arxiv.org/pdf/1711.05101.pdf)\n",
        "            optimizer = optim.AdamW(\n",
        "                self.parameters(), **self.hparams.optimizer_hparams)\n",
        "        elif self.hparams.optimizer_name == \"SGD\":\n",
        "            optimizer = optim.SGD(self.parameters(), **self.hparams.optimizer_hparams)\n",
        "        else:\n",
        "            assert False, f\"Unknown optimizer: \\\"{self.hparams.optimizer_name}\\\"\"\n",
        "\n",
        "        # Kami akan menurunkan learning rate sebanyak 0.1 setelah 100 dan 150 epochs\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(\n",
        "            optimizer, milestones=[100, 150], gamma=0.1)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # \"batch\" adalah output dari training data loader.\n",
        "        imgs, labels = batch\n",
        "        preds = self.model(imgs)\n",
        "        loss = self.loss_module(preds, labels)\n",
        "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
        "\n",
        "        # Mencatat akurasi setiap epoch ke tensorboard (rata - rata tertimbang di atas batch)\n",
        "        self.log('train_acc', acc, on_step=False, on_epoch=True)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss  # Return tensor untuk memanggil \".backward\" kembali\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        preds = self.model(imgs).argmax(dim=-1)\n",
        "        acc = (labels == preds).float().mean()\n",
        "        # Secara standar mencatat setiap epoch (rata - rata tertimbang di atas batch)\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "        preds = self.model(imgs).argmax(dim=-1)\n",
        "        acc = (labels == preds).float().mean()\n",
        "        # Secara standar mencatat setiap epoch (rata - rata tertimbang di atas batch), dan mengembalikannya setelah itu\n",
        "        self.log('test_acc', acc)"
      ],
      "metadata": {
        "id": "RPlNHHurgUO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks \n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint"
      ],
      "metadata": {
        "id": "WUlB1_EhRzLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = {}\n",
        "\n",
        "def create_model(model_name, model_hparams):\n",
        "    if model_name in model_dict:\n",
        "        return model_dict[model_name](**model_hparams)\n",
        "    else:\n",
        "        assert False, f\"Unknown model name \\\"{model_name}\\\". Available models are: {str(model_dict.keys())}\""
      ],
      "metadata": {
        "id": "18jbflowSd0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act_fn_by_name = {\n",
        "    \"tanh\": nn.Tanh,\n",
        "    \"relu\": nn.ReLU,\n",
        "    \"leakyrelu\": nn.LeakyReLU,\n",
        "    \"gelu\": nn.GELU\n",
        "}"
      ],
      "metadata": {
        "id": "DcbmCv-tSfow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model_name, save_name=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
        "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
        "    \"\"\"\n",
        "    if save_name is None:\n",
        "        save_name = model_name\n",
        "        \n",
        "    # Buat PyTorch Lightning trainer dengan generation callback\n",
        "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),                          \n",
        "                         gpus=1 if str(device)==\"cuda:0\" else 0,                                             \n",
        "                         max_epochs=180,                                                                     \n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),  \n",
        "                                    LearningRateMonitor(\"epoch\")],                                           \n",
        "                         progress_bar_refresh_rate=1)                                                        \n",
        "    trainer.logger._log_graph = True         # Jika benar, kami memasukkan hasil komputasi ke dalam grafik di tensorboard\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument yang tidak kita butuhkan\n",
        "    \n",
        "    # Memeriksa model pra training ada. Jika iya, muat dan lewati training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, save_name + \".ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
        "        model = CIFARModule.load_from_checkpoint(pretrained_filename) # Secara otomatis memuat model dengan hyperparameters yang disimpan\n",
        "    else:\n",
        "        pl.seed_everything(42) # Dapat direproduksi\n",
        "        model = CIFARModule(model_name=model_name, **kwargs)\n",
        "        trainer.fit(model, train_loader, val_loader)\n",
        "        model = CIFARModule.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Muat checkpoint terbaik setelah training\n",
        "        \n",
        "    # Uji model terbaik pada validasi dan set pengujian\n",
        "    val_result = trainer.test(model, val_loader, verbose=False)\n",
        "    test_result = trainer.test(model, test_loader, verbose=False)\n",
        "    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n",
        "    \n",
        "    return model, result"
      ],
      "metadata": {
        "id": "54AaiJ_zUVq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, c_red : dict, c_out : dict, act_fn):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Number of input feature maps from the previous layers\n",
        "            c_red - Dictionary with keys \"3x3\" and \"5x5\" specifying the output of the dimensionality reducing 1x1 convolutions\n",
        "            c_out - Dictionary with keys \"1x1\", \"3x3\", \"5x5\", and \"max\"\n",
        "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        \n",
        "        # 1x1 convolution branch\n",
        "        self.conv_1x1 = nn.Sequential(\n",
        "            nn.Conv2d(c_in, c_out[\"1x1\"], kernel_size=1),\n",
        "            nn.BatchNorm2d(c_out[\"1x1\"]),\n",
        "            act_fn()\n",
        "        )\n",
        "        \n",
        "        # 3x3 convolution branch\n",
        "        self.conv_3x3 = nn.Sequential(\n",
        "            nn.Conv2d(c_in, c_red[\"3x3\"], kernel_size=1),\n",
        "            nn.BatchNorm2d(c_red[\"3x3\"]),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_red[\"3x3\"], c_out[\"3x3\"], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(c_out[\"3x3\"]),\n",
        "            act_fn()\n",
        "        )\n",
        "        \n",
        "        # 5x5 convolution branch\n",
        "        self.conv_5x5 = nn.Sequential(\n",
        "            nn.Conv2d(c_in, c_red[\"5x5\"], kernel_size=1),\n",
        "            nn.BatchNorm2d(c_red[\"5x5\"]),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_red[\"5x5\"], c_out[\"5x5\"], kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(c_out[\"5x5\"]),\n",
        "            act_fn()\n",
        "        )\n",
        "        \n",
        "        # Max-pool branch\n",
        "        self.max_pool = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
        "            nn.Conv2d(c_in, c_out[\"max\"], kernel_size=1),\n",
        "            nn.BatchNorm2d(c_out[\"max\"]),\n",
        "            act_fn()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_1x1 = self.conv_1x1(x)\n",
        "        x_3x3 = self.conv_3x3(x)\n",
        "        x_5x5 = self.conv_5x5(x)\n",
        "        x_max = self.max_pool(x)\n",
        "        x_out = torch.cat([x_1x1, x_3x3, x_5x5, x_max], dim=1)\n",
        "        return x_out"
      ],
      "metadata": {
        "id": "6hF76ZXLavaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogleNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10, act_fn_name=\"relu\", **kwargs):\n",
        "        super().__init__()\n",
        "        self.hparams = SimpleNamespace(num_classes=num_classes,\n",
        "                                       act_fn_name=act_fn_name,\n",
        "                                       act_fn=act_fn_by_name[act_fn_name])\n",
        "        self._create_network()\n",
        "        self._init_params()\n",
        "\n",
        "    def _create_network(self):\n",
        "        # A first convolution on the original image to scale up the channel size\n",
        "        self.input_net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            self.hparams.act_fn()\n",
        "        )\n",
        "        # Stacking inception blocks\n",
        "        self.inception_blocks = nn.Sequential(\n",
        "            InceptionBlock(64, c_red={\"3x3\": 32, \"5x5\": 16}, c_out={\"1x1\": 16, \"3x3\": 32, \"5x5\": 8, \"max\": 8}, act_fn=self.hparams.act_fn),\n",
        "            InceptionBlock(64, c_red={\"3x3\": 32, \"5x5\": 16}, c_out={\"1x1\": 24, \"3x3\": 48, \"5x5\": 12, \"max\": 12}, act_fn=self.hparams.act_fn),\n",
        "            nn.MaxPool2d(3, stride=2, padding=1),  # 32x32 => 16x16\n",
        "            InceptionBlock(96, c_red={\"3x3\": 32, \"5x5\": 16}, c_out={\"1x1\": 24, \"3x3\": 48, \"5x5\": 12, \"max\": 12}, act_fn=self.hparams.act_fn),\n",
        "            InceptionBlock(96, c_red={\"3x3\": 32, \"5x5\": 16}, c_out={\"1x1\": 16, \"3x3\": 48, \"5x5\": 16, \"max\": 16}, act_fn=self.hparams.act_fn),\n",
        "            InceptionBlock(96, c_red={\"3x3\": 32, \"5x5\": 16}, c_out={\"1x1\": 16, \"3x3\": 48, \"5x5\": 16, \"max\": 16}, act_fn=self.hparams.act_fn),\n",
        "            InceptionBlock(96, c_red={\"3x3\": 32, \"5x5\": 16}, c_out={\"1x1\": 32, \"3x3\": 48, \"5x5\": 24, \"max\": 24}, act_fn=self.hparams.act_fn),\n",
        "            nn.MaxPool2d(3, stride=2, padding=1),  # 16x16 => 8x8\n",
        "            InceptionBlock(128, c_red={\"3x3\": 48, \"5x5\": 16}, c_out={\"1x1\": 32, \"3x3\": 64, \"5x5\": 16, \"max\": 16}, act_fn=self.hparams.act_fn),\n",
        "            InceptionBlock(128, c_red={\"3x3\": 48, \"5x5\": 16}, c_out={\"1x1\": 32, \"3x3\": 64, \"5x5\": 16, \"max\": 16}, act_fn=self.hparams.act_fn)\n",
        "        )\n",
        "        # Mapping to classification output\n",
        "        self.output_net = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, self.hparams.num_classes)\n",
        "        )\n",
        "\n",
        "    def _init_params(self):\n",
        "        # Based on our discussion in Tutorial 4, we should initialize the convolutions according to the activation function\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(\n",
        "                    m.weight, nonlinearity=self.hparams.act_fn_name)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_net(x)\n",
        "        x = self.inception_blocks(x)\n",
        "        x = self.output_net(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "q9hWJWyLbRiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict[\"GoogleNet\"] = GoogleNet"
      ],
      "metadata": {
        "id": "AjZCyMK9bvsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "googlenet_model, googlenet_results = train_model(model_name=\"GoogleNet\", \n",
        "                                                 model_hparams={\"num_classes\": 10, \n",
        "                                                                \"act_fn_name\": \"relu\"}, \n",
        "                                                 optimizer_name=\"Adam\",\n",
        "                                                 optimizer_hparams={\"lr\": 1e-3,\n",
        "                                                                    \"weight_decay\": 1e-4})"
      ],
      "metadata": {
        "id": "n2l5zCOzdxW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GoogleNet Results\", googlenet_results)"
      ],
      "metadata": {
        "id": "chPVZqdzeIeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tensorboard extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "e-Sfcy1_esKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Opens tensorboard in notebook. Adjust the path to your CHECKPOINT_PATH!\n",
        "%tensorboard --logdir ../saved_models/tensorboards/GoogleNet/"
      ],
      "metadata": {
        "id": "Vvk9bTdTe45x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, act_fn, subsample=False, c_out=-1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Number of input features\n",
        "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
        "            subsample - If True, we want to apply a stride inside the block and reduce the output shape by 2 in height and width\n",
        "            c_out - Number of output features. Note that this is only relevant if subsample is True, as otherwise, c_out = c_in\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        if not subsample:\n",
        "            c_out = c_in\n",
        "            \n",
        "        # Network representing F\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, stride=1 if not subsample else 2, bias=False),  # No bias needed as the Batch Norm handles it\n",
        "            nn.BatchNorm2d(c_out),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(c_out)\n",
        "        )\n",
        "        \n",
        "        # 1x1 convolution with stride 2 means we take the upper left value, and transform it to new output size\n",
        "        self.downsample = nn.Conv2d(c_in, c_out, kernel_size=1, stride=2) if subsample else None\n",
        "        self.act_fn = act_fn()\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.net(x)\n",
        "        if self.downsample is not None:\n",
        "            x = self.downsample(x)\n",
        "        out = z + x\n",
        "        out = self.act_fn(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "xm9aKt0dFiUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PreActResNetBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, act_fn, subsample=False, c_out=-1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Number of input features\n",
        "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
        "            subsample - If True, we want to apply a stride inside the block and reduce the output shape by 2 in height and width\n",
        "            c_out - Number of output features. Note that this is only relevant if subsample is True, as otherwise, c_out = c_in\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        if not subsample:\n",
        "            c_out = c_in\n",
        "            \n",
        "        # Network representing F\n",
        "        self.net = nn.Sequential(\n",
        "            nn.BatchNorm2d(c_in),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, stride=1 if not subsample else 2, bias=False),\n",
        "            nn.BatchNorm2d(c_out),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1, bias=False)\n",
        "        )\n",
        "        \n",
        "        # 1x1 convolution needs to apply non-linearity as well as not done on skip connection\n",
        "        self.downsample = nn.Sequential(\n",
        "            nn.BatchNorm2d(c_in),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_in, c_out, kernel_size=1, stride=2, bias=False)\n",
        "        ) if subsample else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.net(x)\n",
        "        if self.downsample is not None:\n",
        "            x = self.downsample(x)\n",
        "        out = z + x\n",
        "        return out"
      ],
      "metadata": {
        "id": "BnhlkgPNGVK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_blocks_by_name = {\n",
        "    \"ResNetBlock\": ResNetBlock,\n",
        "    \"PreActResNetBlock\": PreActResNetBlock\n",
        "}"
      ],
      "metadata": {
        "id": "mQX22wG_HDJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10, num_blocks=[3,3,3], c_hidden=[16,32,64], act_fn_name=\"relu\", block_name=\"ResNetBlock\", **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs: \n",
        "            num_classes - Number of classification outputs (10 for CIFAR10)\n",
        "            num_blocks - List with the number of ResNet blocks to use. The first block of each group uses downsampling, except the first.\n",
        "            c_hidden - List with the hidden dimensionalities in the different blocks. Usually multiplied by 2 the deeper we go.\n",
        "            act_fn_name - Name of the activation function to use, looked up in \"act_fn_by_name\"\n",
        "            block_name - Name of the ResNet block, looked up in \"resnet_blocks_by_name\"\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert block_name in resnet_blocks_by_name\n",
        "        self.hparams = SimpleNamespace(num_classes=num_classes, \n",
        "                                       c_hidden=c_hidden, \n",
        "                                       num_blocks=num_blocks, \n",
        "                                       act_fn_name=act_fn_name,\n",
        "                                       act_fn=act_fn_by_name[act_fn_name],\n",
        "                                       block_class=resnet_blocks_by_name[block_name])\n",
        "        self._create_network()\n",
        "        self._init_params()\n",
        "\n",
        "    def _create_network(self):\n",
        "        c_hidden = self.hparams.c_hidden\n",
        "        \n",
        "        # A first convolution on the original image to scale up the channel size\n",
        "        if self.hparams.block_class == PreActResNetBlock: # => Don't apply non-linearity on output\n",
        "            self.input_net = nn.Sequential(\n",
        "                nn.Conv2d(3, c_hidden[0], kernel_size=3, padding=1, bias=False)\n",
        "            )\n",
        "        else:\n",
        "            self.input_net = nn.Sequential(\n",
        "                nn.Conv2d(3, c_hidden[0], kernel_size=3, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(c_hidden[0]),\n",
        "                self.hparams.act_fn()\n",
        "            )\n",
        "        \n",
        "        # Creating the ResNet blocks\n",
        "        blocks = []\n",
        "        for block_idx, block_count in enumerate(self.hparams.num_blocks):\n",
        "            for bc in range(block_count):\n",
        "                subsample = (bc == 0 and block_idx > 0) # Subsample the first block of each group, except the very first one.\n",
        "                blocks.append(\n",
        "                    self.hparams.block_class(c_in=c_hidden[block_idx if not subsample else (block_idx-1)],\n",
        "                                             act_fn=self.hparams.act_fn,\n",
        "                                             subsample=subsample,\n",
        "                                             c_out=c_hidden[block_idx])\n",
        "                )\n",
        "        self.blocks = nn.Sequential(*blocks)\n",
        "        \n",
        "        # Mapping to classification output\n",
        "        self.output_net = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(c_hidden[-1], self.hparams.num_classes)\n",
        "        )\n",
        "\n",
        "    def _init_params(self):\n",
        "        # Based on our discussion in Tutorial 4, we should initialize the convolutions according to the activation function\n",
        "        # Fan-out focuses on the gradient distribution, and is commonly used in ResNets\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity=self.hparams.act_fn_name)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_net(x)\n",
        "        x = self.blocks(x)\n",
        "        x = self.output_net(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "6eH5YiSuKWEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict[\"ResNet\"] = ResNet"
      ],
      "metadata": {
        "id": "PUM_JYnZKWzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model, resnet_results = train_model(model_name=\"ResNet\", \n",
        "                                           model_hparams={\"num_classes\": 10,\n",
        "                                                          \"c_hidden\": [16,32,64],\n",
        "                                                          \"num_blocks\": [3,3,3],\n",
        "                                                          \"act_fn_name\": \"relu\"}, \n",
        "                                           optimizer_name=\"SGD\",\n",
        "                                           optimizer_hparams={\"lr\": 0.1,\n",
        "                                                              \"momentum\": 0.9,\n",
        "                                                              \"weight_decay\": 1e-4})"
      ],
      "metadata": {
        "id": "zWuj672AKZhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnetpreact_model, resnetpreact_results = train_model(model_name=\"ResNet\", \n",
        "                                                       model_hparams={\"num_classes\": 10,\n",
        "                                                                      \"c_hidden\": [16,32,64],\n",
        "                                                                      \"num_blocks\": [3,3,3],\n",
        "                                                                      \"act_fn_name\": \"relu\",\n",
        "                                                                      \"block_name\": \"PreActResNetBlock\"}, \n",
        "                                                       optimizer_name=\"SGD\",\n",
        "                                                       optimizer_hparams={\"lr\": 0.1,\n",
        "                                                                          \"momentum\": 0.9,\n",
        "                                                                          \"weight_decay\": 1e-4},\n",
        "                                                       save_name=\"ResNetPreAct\")"
      ],
      "metadata": {
        "id": "GWBzRNe-L_63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Opens tensorboard in notebook. Adjust the path to your CHECKPOINT_PATH! Feel free to change \"ResNet\" to \"ResNetPreAct\"\n",
        "%tensorboard --logdir ../saved_models/tensorboards/ResNet/"
      ],
      "metadata": {
        "id": "nTVYI47COJVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, bn_size, growth_rate, act_fn):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Number of input channels\n",
        "            bn_size - Bottleneck size (factor of growth rate) for the output of the 1x1 convolution. Typically between 2 and 4.\n",
        "            growth_rate - Number of output channels of the 3x3 convolution\n",
        "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.BatchNorm2d(c_in),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_in, bn_size * growth_rate, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(bn_size * growth_rate),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(bn_size * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        out = torch.cat([out, x], dim=1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "_C3OmVEhP46R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, num_layers, bn_size, growth_rate, act_fn):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Number of input channels\n",
        "            num_layers - Number of dense layers to apply in the block\n",
        "            bn_size - Bottleneck size to use in the dense layers\n",
        "            growth_rate - Growth rate to use in the dense layers\n",
        "            act_fn - Activation function to use in the dense layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        for layer_idx in range(num_layers):\n",
        "            layers.append(\n",
        "                DenseLayer(c_in=c_in + layer_idx * growth_rate, # Input channels are original plus the feature maps from previous layers\n",
        "                           bn_size=bn_size,\n",
        "                           growth_rate=growth_rate,\n",
        "                           act_fn=act_fn)\n",
        "            )\n",
        "        self.block = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.block(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "k0jUzrMeQRnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransitionLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, c_in, c_out, act_fn):\n",
        "        super().__init__()\n",
        "        self.transition = nn.Sequential(\n",
        "            nn.BatchNorm2d(c_in),\n",
        "            act_fn(),\n",
        "            nn.Conv2d(c_in, c_out, kernel_size=1, bias=False),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2) # Average the output for each 2x2 pixel group\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.transition(x)"
      ],
      "metadata": {
        "id": "Tt4ZPaPMQ5RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes=10, num_layers=[6,6,6,6], bn_size=2, growth_rate=16, act_fn_name=\"relu\", **kwargs):\n",
        "        super().__init__()\n",
        "        self.hparams = SimpleNamespace(num_classes=num_classes,\n",
        "                                       num_layers=num_layers,\n",
        "                                       bn_size=bn_size,\n",
        "                                       growth_rate=growth_rate,\n",
        "                                       act_fn_name=act_fn_name,\n",
        "                                       act_fn=act_fn_by_name[act_fn_name])\n",
        "        self._create_network()\n",
        "        self._init_params()\n",
        "        \n",
        "    def _create_network(self):\n",
        "        c_hidden = self.hparams.growth_rate * self.hparams.bn_size # The start number of hidden channels\n",
        "        \n",
        "        # A first convolution on the original image to scale up the channel size\n",
        "        self.input_net = nn.Sequential(\n",
        "            nn.Conv2d(3, c_hidden, kernel_size=3, padding=1) # No batch norm or activation function as done inside the Dense layers\n",
        "        )\n",
        "        \n",
        "        # Creating the dense blocks, eventually including transition layers\n",
        "        blocks = []\n",
        "        for block_idx, num_layers in enumerate(self.hparams.num_layers):\n",
        "            blocks.append( \n",
        "                DenseBlock(c_in=c_hidden, \n",
        "                           num_layers=num_layers, \n",
        "                           bn_size=self.hparams.bn_size,\n",
        "                           growth_rate=self.hparams.growth_rate,\n",
        "                           act_fn=self.hparams.act_fn)\n",
        "            )\n",
        "            c_hidden = c_hidden + num_layers * self.hparams.growth_rate # Overall output of the dense block\n",
        "            if block_idx < len(self.hparams.num_layers)-1: # Don't apply transition layer on last block\n",
        "                blocks.append(\n",
        "                    TransitionLayer(c_in=c_hidden,\n",
        "                                    c_out=c_hidden // 2,\n",
        "                                    act_fn=self.hparams.act_fn))\n",
        "                c_hidden = c_hidden // 2\n",
        "                \n",
        "        self.blocks = nn.Sequential(*blocks)\n",
        "        \n",
        "        # Mapping to classification output\n",
        "        self.output_net = nn.Sequential(\n",
        "            nn.BatchNorm2d(c_hidden), # The features have not passed a non-linearity until here.\n",
        "            self.hparams.act_fn(),\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(c_hidden, self.hparams.num_classes)\n",
        "        )\n",
        "\n",
        "    def _init_params(self):\n",
        "        # Based on our discussion in Tutorial 4, we should initialize the convolutions according to the activation function\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity=self.hparams.act_fn_name)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_net(x)\n",
        "        x = self.blocks(x)\n",
        "        x = self.output_net(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rVQ8MDzyRS0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict[\"DenseNet\"] = DenseNet"
      ],
      "metadata": {
        "id": "yT3HKR5fSFwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "densenet_model, densenet_results = train_model(model_name=\"DenseNet\", \n",
        "                                               model_hparams={\"num_classes\": 10,\n",
        "                                                              \"num_layers\": [6,6,6,6],\n",
        "                                                              \"bn_size\": 2,\n",
        "                                                              \"growth_rate\": 16,\n",
        "                                                              \"act_fn_name\": \"relu\"}, \n",
        "                                               optimizer_name=\"Adam\",\n",
        "                                               optimizer_hparams={\"lr\": 1e-3,\n",
        "                                                                  \"weight_decay\": 1e-4})"
      ],
      "metadata": {
        "id": "oMjK5WyJSpOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!-- Some HTML code to increase font size in the following table -->\n",
        "<style>\n",
        "th {font-size: 120%;}\n",
        "td {font-size: 120%;}\n",
        "</style>"
      ],
      "metadata": {
        "id": "FxoO4w-LTipW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tabulate\n",
        "from IPython.display import display, HTML\n",
        "all_models = [\n",
        "    (\"GoogleNet\", googlenet_results, googlenet_model),\n",
        "    (\"ResNet\", resnet_results, resnet_model),\n",
        "    (\"ResNetPreAct\", resnetpreact_results, resnetpreact_model),\n",
        "    (\"DenseNet\", densenet_results, densenet_model)\n",
        "]\n",
        "table = [[model_name,\n",
        "          f\"{100.0*model_results['val']:4.2f}%\",\n",
        "          f\"{100.0*model_results['test']:4.2f}%\",\n",
        "          \"{:,}\".format(sum([np.prod(p.shape) for p in model.parameters()]))]\n",
        "         for model_name, model_results, model in all_models]\n",
        "display(HTML(tabulate.tabulate(table, tablefmt='html', headers=[\"Model\", \"Val Accuracy\", \"Test Accuracy\", \"Num Parameters\"])))"
      ],
      "metadata": {
        "id": "DzwUhf_vTj_i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}